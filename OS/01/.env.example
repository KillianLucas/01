### SETTINGS
# Copy this file and rename it to ".env" to use it.

# If ALL_LOCAL is False, we'll use OpenAI's services
# If setting ALL_LOCAL to true, set the path to the WHISPER local model
ALL_LOCAL=False
# WHISPER_MODEL_PATH=...
# OPENAI_API_KEY=sk-...

# Expose through Ngrok
# Uncomment following line with your Ngrok auth token (https://dashboard.ngrok.com/get-started/your-authtoken)
# export NGROK_AUTHTOKEN="AUTH_TOKEN"

# For TTS, we use the en_US-lessac-medium voice model by default
# Please change the voice URL and voice name if you wish to use another voice
export PIPER_VOICE_URL="https://huggingface.co/rhasspy/piper-voices/resolve/main/en/en_US/lessac/medium/"
export PIPER_VOICE_NAME="en_US-lessac-medium.onnx"

# If SERVER_START, this is where we'll serve the server.
# If DEVICE_START, this is where the device expects the server to be.
SERVER_URL=ws://localhost:8000/
SERVER_CONNECTION_URL=ws://localhost:8000/ # Comment if setting up through Ngrok
SERVER_START=True
DEVICE_START=True

# Control where various operations happenâ€” can be `device` or `server`.
CODE_RUNNER=server
TTS_RUNNER=server # If device, audio will be sent over websocket.
STT_RUNNER=device # If server, audio will be sent over websocket.

# Will expose the server publically and display that URL.
SERVER_EXPOSE_PUBLICALLY=False

# Debug level
# LOG_LEVEL=DEBUG
LOG_LEVEL="INFO"